[RAG]
# RAG aktivieren (1) oder deaktivieren (0)
enabled = 1

[APP]
# App-/Build-Version (Anzeige)
version = 3.0
# Tarifdaten-Version und Stichtag (Anzeige)
tarif_version = Tarifversion 1.1c, Stand 08.08.2025

[LLM1UND2]
# Provider fuer Stufe 1 (gemini|openai|apertus|ollama)
# Modell fuer Stufe 1
# Provider fuer Stufe 2
# Modell fuer Stufe 2

# SwissAI
# stage1_provider = apertus
# stage1_model = swiss-ai/apertus-70b-instruct
# stage1_model = openai/gpt-oss-120b
# stage2_provider = apertus
# stage2_model = swiss-ai/apertus-70b-instruct
# stage2_model = openai/gpt-oss-120b

# Gemini (Google)
stage1_provider = gemini
stage1_model = gemini-2.5-flash
stage2_provider = gemini
stage2_model = gemini-2.5-flash

# GPT (OpenAI)
# stage1_provider = openai
# stage1_model = gpt-5
# stage2_provider = openai
# stage2_model = gpt-5

[SYNONYMS]
# RAG Embedding nutzt Basistext; Synonyme in Keyword‑Suche berücksichtigt, wenn (1), ansonsten (0)
enabled = 1
# Dateiname des Synonymkatalogs (JSON)
catalog_filename = synonyms.json
# Provider fuer Synonym-LLM
llm_provider = gemini
# Modell fuer Synonym-LLM
llm_model = gemini-2.5-flash
# Fenstergeometrie Liste (Breite x Hoehe + X + Y)
list_geometry = 1200x700+182+182
# Spaltenbreiten der Liste (CSV)
list_columns = 90,360,1200,20
# Fenstergeometrie Editor (Breite x Hoehe + X + Y)
edit_geometry = 600x400+208+208
# Spaltenbreiten des Editors (CSV)
edit_columns = 184,404

[REGELPRUEFUNG]
# Kumulation nur bei ausdruecklicher Anforderung (1) sonst Standard (0 = Jede Kumulation, wenn nicht ausdrücklich verboten)
kumulation_explizit = 0

[LOGGING]
# Dateilogging aktivieren (1) oder deaktivieren (0)
file_enabled = 1
# Datei-Pfad fuer Logs (z. B. logs/app.log)
file_path = logs/app.log
# Max. Dateigroesse vor Rotation (Bytes)
file_max_bytes = 10000000
# Anzahl Aufbewahrungen (rotierte Dateien)
file_backup_count = 5
# Eigenes Log-Level fuer Datei (z. B. INFO)
file_level = INFO

[LLM]
# Globale Steuerung für LLM-Aufruffrequenz
# Mindestabstand zwischen zwei LLM-Aufrufen in Sekunden
# 0 = kein Warten (sofort)
# 1-1000 = n Sekunden warten bis zum nächsten Aufruf
min_call_interval_seconds = 2

[LLM_CAPABILITIES]
# Feature-Flag: unterstuetzt Temperature (1/0)
gpt-5-mini_supports_temperature = 0
# Feature-Flag: unterstuetzt Temperature (1/0)
gpt-5_supports_temperature = 0

[OPENAI]
# Timeout fuer OpenAI-kompatible APIs (Sekunden)
timeout = 180
# Maximal erzeugte Output-Tokens
max_output_tokens = 20000
# Maximal erzeugte Output-Tokens fuer Apertus (OpenAI-kompatibel)
max_output_tokens_apertus = 5000
# Standard Token-Budget fuer Eingabe (nicht Apertus)
token_budget_default = 100000
# Token-Budget fuer Apertus-Eingänge
token_budget_apertus = 15000
# Prompt-Trimmen fuer Apertus aktivieren (1/0)
trim_apertus_enabled = 0
# Max. Trim-Durchlaeufe bei Apertus
trim_max_passes = 3
# Untergrenze fuer das Trimmen des Kontexts bei Apertus
trim_min_context_chars = 5000
# Anzahl Wiederholungen bei Serverfehlern (HTTP 5xx) in Stufe 1
# Beispiel: 0 = kein Retry, 1 = einmal wiederholen, 3 = drei Wiederholungen
server_error_max_retries = 5
# Wartezeit zwischen Wiederholungen (Sekunden)
server_error_retry_delay_seconds = 2

[GEMINI]
# Timeout fuer Gemini (Sekunden)
timeout = 120
# 0 = Trimmen aus; 1 = Trimmen an (nur Stage 1 Prompt)
trim_enabled = 0
# Token-Budget für Eingabe-Prompt; bei Überschreitung wird Kontext gekürzt
token_budget = 50000
# Untergrenze für das Trimmen des Kontexts
trim_min_context_chars = 30000
# Anzahl Wiederholungen bei Serverfehlern (HTTP 5xx) in Stufe 1
# Beispiel: 0 = kein Retry, 1 = einmal wiederholen, 3 = drei Wiederholungen
server_error_max_retries = 3
# Wartezeit zwischen Wiederholungen (Sekunden)
server_error_backoff_seconds = 1

[API_ENDPOINTS]
# Basis-URL fuer Apertus (OpenAI-kompatibel)
apertus_base_url = https://api.publicai.co/v1
# Basis-URL fuer OpenAI
openai_base_url = https://api.openai.com/v1

# Kontextsteuerung: reduziere Eingabetokens gezielt
[CONTEXT]
# 1 = einschliessen, 0 = weglassen
# Med. Interpretation in Kontext aufnehmen (1/0)
include_med_interpretation = 1
# Typ /E/EZ und P/PZ) in Kontext aufnehmen (Standard und zwingend = 1/0)
include_typ = 1
# Beschreibung in Kontext aufnehmen (Standard und zwingend= 1/0)
include_beschreibung = 1
# Maximale Anzahl Kontextzeilen (0 = unbegrenzt)
max_context_items = 0
# Immer aufnehmen (Kommagetrennt), z. B. Konsultations-Grundpositionen
# Liste von Codewerten, die immer in den Kontext müssen (CSV)
force_include_codes = AA.00.0010, CA.00.0010, AA.00.0020, CA.00.0020